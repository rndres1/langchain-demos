{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7be03f-dc6c-42b6-80e3-0fe960651e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "openai_llm = OpenAI(temperature=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645a822-d8e9-428d-b3d3-346626661bcb",
   "metadata": {},
   "source": [
    "### Example 1: Using PromptTemplate -- write a list of jokes, then a second list of jokes very similar to the first one but on a different topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4f0b40-0094-4354-8a3a-e47f4185572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = ['computer scientists', 'truck drivers', 'lawyers', 'accountants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e91998-478d-4486-bc74-9f9bf8f09c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profession1 = professions[0]\n",
    "prompt1 = f\"Write 7 jokes about {profession1}.\"\n",
    "resp1 = openai_llm(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8909bbad-7368-4f75-8c05-2a83faa3d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What did the computer scientist say when he found a big bug in his code? \"That's not a bug, that's a feature!\"\n",
      "\n",
      "2. Why did the computer scientist cross the road? To get to the other side of the algorithm.\n",
      "\n",
      "3. What did the computer scientist say when he was asked to debug a program? \"I'm no magician, I'm a computer scientist!\"\n",
      "\n",
      "4. What did the computer scientist say when his computer crashed? \"It must have been a logic error!\"\n",
      "\n",
      "5. Why did the computer scientist keep dropping his keys? He was trying to find the key to the algorithm.\n",
      "\n",
      "6. How did the computer scientist propose to his girlfriend? With a binary search tree.\n",
      "\n",
      "7. What did the computer scientist say when he saw a broken computer? \"It looks like it needs a few lines of code.\"\n"
     ]
    }
   ],
   "source": [
    "print (resp1.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c056921a-fa1e-4762-a30e-365d9aa9709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Given below is a numbered list of jokes about {profession1}. \n",
    "Riff on these jokes to make equal number of very similar jokes about {profession2}. \n",
    "Do not add any explanation, elaboration or any additional comments.\n",
    "---\n",
    "{jokes_output}\n",
    "\"\"\"\n",
    "p_template = PromptTemplate(input_variables=['profession1', 'profession2', 'jokes_output'], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaeff67-f25b-46ca-8fee-9d96b2878236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================truck drivers=====================\n",
      "1. What did the truck driver say when he found a big pothole in the road? \"That's not a pothole, that's a shortcut!\"\n",
      "\n",
      "2. Why did the truck driver cross the road? To get to the other side of the highway.\n",
      "\n",
      "3. What did the truck driver say when he was asked to drive through a storm? \"I'm no miracle worker, I'm a truck driver!\"\n",
      "\n",
      "4. What did the truck driver say when his truck broke down? \"It must have been a fuel error!\"\n",
      "\n",
      "5. Why did the truck driver keep dropping his keys? He was trying to find the key to the ignition.\n",
      "\n",
      "6. How did the truck driver propose to his girlfriend? With a long haul.\n",
      "\n",
      "7. What did the truck driver say when he saw a broken-down truck? \"It looks like it needs a few gallons of gas.\"\n",
      "=======================lawyers=====================\n",
      "1. What did the lawyer say when he found a loophole in the contract? \"That's not a loophole, that's a feature!\"\n",
      "\n",
      "2. Why did the lawyer cross the road? To get to the other side of the argument.\n",
      "\n",
      "3. What did the lawyer say when he was asked to defend a client? \"I'm no magician, I'm a lawyer!\"\n",
      "\n",
      "4. What did the lawyer say when his case was dismissed? \"It must have been a legal error!\"\n",
      "\n",
      "5. Why did the lawyer keep dropping his keys? He was trying to find the key to the case.\n",
      "\n",
      "6. How did the lawyer propose to his girlfriend? With a legal brief.\n",
      "\n",
      "7. What did the lawyer say when he saw a broken contract? \"It looks like it needs a few lines of text.\"\n",
      "=======================accountants=====================\n",
      "1. What did the accountant say when he found a big mistake in his books? \"That's not a mistake, that's an adjustment!\"\n",
      "\n",
      "2. Why did the accountant cross the road? To get to the other side of the balance sheet.\n",
      "\n",
      "3. What did the accountant say when he was asked to audit a company? \"I'm no miracle worker, I'm an accountant!\"\n",
      "\n",
      "4. What did the accountant say when his computer crashed? \"It must have been a miscalculation!\"\n",
      "\n",
      "5. Why did the accountant keep dropping his keys? He was trying to find the key to the ledger.\n",
      "\n",
      "6. How did the accountant propose to his girlfriend? With a double-entry bookkeeping system.\n",
      "\n",
      "7. What did the accountant say when he saw a broken computer? \"It looks like it needs a few entries in the spreadsheet.\"\n"
     ]
    }
   ],
   "source": [
    "for profession2 in professions[1:]:\n",
    "    prompt2 = p_template.format(profession2=profession2, jokes_output=resp1, profession1=profession1)\n",
    "    resp2 = openai_llm(prompt2)\n",
    "    print (f\"======================={profession2}=====================\")\n",
    "    print (resp2.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047be133-0b97-463c-9982-e51a23205600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff2500d-9f0d-4f53-b0ad-80582ecb6ac9",
   "metadata": {},
   "source": [
    "### Example 2 : using LLMchain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
